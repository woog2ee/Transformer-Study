{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### set device and data"
      ],
      "metadata": {
        "id": "5hXkBJT2DsVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'using device: {device}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfEgZTu7hGWI",
        "outputId": "2e4408f2-e99c-430c-caa3-87b2140be483"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def file2list(file):\n",
        "    lst = []\n",
        "    for line in open(f'./{file}', 'r', encoding='utf-8-sig'):\n",
        "      line = line.replace('\\n', '')\n",
        "      lst.append(line)\n",
        "    return lst\n",
        "\n",
        "# train, valid, test texts\n",
        "en_train_lst = file2list('train.en')\n",
        "en_valid_lst = file2list('val.en')\n",
        "en_test_lst  = file2list('test.en')\n",
        "print(f'en data: {len(en_train_lst), len(en_valid_lst), len(en_test_lst)}')\n",
        "\n",
        "de_train_lst = file2list('train.de')\n",
        "de_valid_lst = file2list('val.de')\n",
        "de_test_lst  = file2list('test.de')\n",
        "print(f'de data: {len(de_train_lst), len(de_valid_lst), len(de_test_lst)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbM-LRoP2uoA",
        "outputId": "026aea19-b216-41ac-ebe0-47835ef34c98"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "en data: (29001, 1015, 1000)\n",
            "de data: (29001, 1015, 1000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### build vocabularies"
      ],
      "metadata": {
        "id": "OqK109CLDzBT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# using spacy tokenizer\n",
        "!python -m spacy download en_core_web_sm\n",
        "!python -m spacy download de_core_news_sm"
      ],
      "metadata": {
        "id": "-ZegqCCcNqMY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dbf473b-2e9f-4299-c2dc-e8264a34729d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-sm==3.4.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.4.0/en_core_web_sm-3.4.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8 MB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-sm==3.4.0) (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.21.6)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.3.0)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.4.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (57.4.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (21.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.11.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.10.1)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.0.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (4.1.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (4.64.1)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.6.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.6)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.4.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (8.1.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.10)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.0.8)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.9.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (5.2.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2022.9.24)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.7.8)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.0.2)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting de-core-news-sm==3.4.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.4.0/de_core_news_sm-3.4.0-py3-none-any.whl (14.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.6 MB 1.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from de-core-news-sm==3.4.0) (3.4.1)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.6.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (4.64.1)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.0.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.0.8)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.0.10)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.9.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.0.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.11.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.4.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.0.6)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (4.1.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.21.6)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.4.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (21.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.23.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.0.8)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.10.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (57.4.0)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (8.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (5.2.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.7.8)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.0.2)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.0.1)\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-3.4.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('de_core_news_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "# using spacy tokenizer\n",
        "en_tokenizer = get_tokenizer(tokenizer='spacy', language='en_core_web_sm')\n",
        "de_tokenizer = get_tokenizer(tokenizer='spacy', language='de_core_news_sm')\n",
        "\n",
        "# vocabulary for training texts\n",
        "en_vocab = build_vocab_from_iterator(map(en_tokenizer, [text for text in en_train_lst]),\n",
        "                                     min_freq=2,\n",
        "                                     specials=['<unk>','<sos>','<eos>','<pad>'],\n",
        "                                     special_first=True)\n",
        "de_vocab = build_vocab_from_iterator(map(de_tokenizer, [text for text in de_train_lst]),\n",
        "                                     min_freq=2,\n",
        "                                     specials=['<unk>','<sos>','<eos>','<pad>'],\n",
        "                                     special_first=True)\n",
        "print(f'en vocab size: {len(en_vocab)}')\n",
        "print(f'de vocab size: {len(de_vocab)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXcQJnCbN1H0",
        "outputId": "7dba4c7a-7e6a-4433-91bb-1e282eaa9280"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "en vocab size: 6191\n",
            "de vocab size: 8014\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### make preprocessor for encode & decode texts"
      ],
      "metadata": {
        "id": "PEAj3JF8D8bX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Preprocessor:\n",
        "  unk_token_id = 0\n",
        "  sos_token_id = 1\n",
        "  eos_token_id = 2\n",
        "  pad_token_id = 3\n",
        "\n",
        "  def __init__(self, src_tokenizer, tgt_tokenizer, src_vocab, tgt_vocab):\n",
        "    self.src_tokenizer = src_tokenizer\n",
        "    self.tgt_tokenizer = tgt_tokenizer\n",
        "\n",
        "    # token -> id\n",
        "    self.src_token2id = src_vocab.get_stoi()\n",
        "    self.tgt_token2id = tgt_vocab.get_stoi()\n",
        "    # id -> token\n",
        "    self.src_id2token = src_vocab.get_itos()\n",
        "    self.tgt_id2token = tgt_vocab.get_itos()\n",
        "\n",
        "  # encode token -> id for source sentence\n",
        "  def src_encode(self, text):\n",
        "    if type(text) == list: text = ' '.join(text)\n",
        "    tokenized = self.src_tokenizer(text)\n",
        "    encoded   = [self.src_token2id.get(token, self.src_token2id['<unk>']) for token in tokenized]\n",
        "    return encoded\n",
        "\n",
        "  # encode token -> id, attach <sos> and <eos> for target sentence\n",
        "  def tgt_encode(self, text):\n",
        "    if type(text) == list: text = ' '.join(text)\n",
        "    tokenized = self.tgt_tokenizer(text)\n",
        "    encoded   = [self.tgt_token2id['<sos>']] \\\n",
        "    + [self.tgt_token2id.get(token, self.tgt_token2id['<unk>']) for token in tokenized] \\\n",
        "    + [self.tgt_token2id['<eos>']]\n",
        "    return encoded\n",
        "\n",
        "  # decode source sentence\n",
        "  def src_decode(self, ids):\n",
        "    decoded = list(map(lambda x: self.src_id2token[x], ids))\n",
        "    return ' '.join(decoded)\n",
        "\n",
        "  # decode target sentence\n",
        "  def tgt_decode(self, ids):\n",
        "    decoded = list(map(lambda x: self.tgt_id2token[x], ids))[1:-1]\n",
        "    return ' '.join(decoded)\n",
        "\n",
        "preprocessor = Preprocessor(en_tokenizer, de_tokenizer, en_vocab, de_vocab)"
      ],
      "metadata": {
        "id": "_sxputetzNrJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### make custom dataset, data loader"
      ],
      "metadata": {
        "id": "uwID8j0DEIGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data.dataset import Dataset\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, en_lst, de_lst, preprocessor):\n",
        "    self.en_lst = en_lst\n",
        "    self.de_lst = de_lst\n",
        "    assert len(self.en_lst) == len(self.de_lst)\n",
        "\n",
        "    self.preprocessor = preprocessor\n",
        "    self.dataset      = self.make_dataset()\n",
        "\n",
        "  # make (en, de) sentence pair dataset\n",
        "  def make_dataset(self):\n",
        "    dataset = [(self.preprocessor.src_encode(en), self.preprocessor.tgt_encode(de))\n",
        "               for en, de in zip(self.en_lst, self.de_lst)\n",
        "               if len(en) > 0 and len(de) > 0]\n",
        "    return dataset\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.dataset[idx]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.dataset)\n",
        "\n",
        "train_dataset = CustomDataset(en_train_lst, de_train_lst, preprocessor)\n",
        "valid_dataset = CustomDataset(en_valid_lst, de_valid_lst, preprocessor)\n",
        "test_dataset  = CustomDataset(en_test_lst, de_test_lst, preprocessor)\n",
        "print(f'dataset size: {len(train_dataset), len(valid_dataset), len(test_dataset)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BobpKq6N7YeR",
        "outputId": "81525994-4573-44ea-8b30-7c45f34cc22a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset size: (29000, 1014, 1000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# sequence padding in batch\n",
        "def collate_fn(batch_samples):\n",
        "  pad_token_id = preprocessor.pad_token_id\n",
        "  src_sent = pad_sequence([torch.tensor(src) for src, _ in batch_samples],\n",
        "                          batch_first=True,\n",
        "                          padding_value=pad_token_id)\n",
        "  tgt_sent = pad_sequence([torch.tensor(tgt) for _, tgt in batch_samples],\n",
        "                          batch_first=True,\n",
        "                          padding_value=pad_token_id)\n",
        "  return src_sent.to(device), tgt_sent.to(device)\n",
        "\n",
        "# composing batch to match similar lengths of sequences\n",
        "def batch_sampling(sequence_lengths, BATCH_SIZE):\n",
        "  seq_lens = [(i, seq_len, tgt_len) for i, (seq_len, tgt_len) in enumerate(sequence_lengths)]\n",
        "  seq_lens = sorted(seq_lens, key=lambda x: x[1])\n",
        "  seq_lens = [sample[0] for sample in seq_lens]\n",
        "\n",
        "  sample_indices = [seq_lens[i:i+BATCH_SIZE] for i in range(0, len(seq_lens), BATCH_SIZE)]\n",
        "  random.shuffle(sample_indices)\n",
        "  return sample_indices\n",
        "\n",
        "# make dataloader using sequence padding & composing batch\n",
        "def make_loader(dataset, BATCH_SIZE):\n",
        "  sequence_lengths = list(map(lambda x: (len(x[0]), len(x[1])), dataset))\n",
        "  batch_sampler = batch_sampling(sequence_lengths, BATCH_SIZE)\n",
        "  loader = DataLoader(dataset,\n",
        "                      collate_fn=collate_fn,\n",
        "                      batch_sampler=batch_sampler)\n",
        "  return loader\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "train_loader = make_loader(train_dataset, BATCH_SIZE)\n",
        "valid_loader = make_loader(valid_dataset, BATCH_SIZE)\n",
        "test_loader  = make_loader(test_dataset, BATCH_SIZE)\n",
        "print('check dataset and batch size,')\n",
        "\n",
        "print(f'train data length       : {len(en_train_lst)}')\n",
        "print(f'train data loader length: {len(train_loader)}')\n",
        "print(f'train data loader length: {len(en_train_lst) / BATCH_SIZE}\\n')\n",
        "\n",
        "print(f'valid data length       : {len(en_valid_lst)}')\n",
        "print(f'valid data loader length: {len(valid_loader)}')\n",
        "print(f'valid data loader length: {len(en_valid_lst) / BATCH_SIZE}\\n')\n",
        "\n",
        "print(f'test data length       : {len(en_test_lst)}')\n",
        "print(f'test data loader length: {len(test_loader)}')\n",
        "print(f'test data loader length: {len(en_test_lst) / BATCH_SIZE}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggu-VvWnA5hR",
        "outputId": "82b16ce8-4937-4149-a54a-cc05e290fa4c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "check dataset and batch size,\n",
            "train data length       : 29001\n",
            "train data loader length: 454\n",
            "train data loader length: 453.140625\n",
            "\n",
            "valid data length       : 1015\n",
            "valid data loader length: 16\n",
            "valid data loader length: 15.859375\n",
            "\n",
            "test data length       : 1000\n",
            "test data loader length: 16\n",
            "test data loader length: 15.625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### multi-head attention, position-wise feed forward"
      ],
      "metadata": {
        "id": "rSD1lAtLEWQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class MultiHeadAttentionLayer(nn.Module):\n",
        "  def __init__(self, hidden_dim, n_heads, dropout_ratio, device):\n",
        "    super().__init__()\n",
        "    assert hidden_dim % n_heads == 0\n",
        "    self.hidden_dim = hidden_dim  \n",
        "    self.n_heads    = n_heads\n",
        "    self.head_dim   = hidden_dim // n_heads  # n_heads * hidden_dim = head_dim\n",
        "\n",
        "    self.fc_query = nn.Linear(hidden_dim, hidden_dim)\n",
        "    self.fc_key   = nn.Linear(hidden_dim, hidden_dim)\n",
        "    self.fc_value = nn.Linear(hidden_dim, hidden_dim)\n",
        "    self.fc_o     = nn.Linear(hidden_dim, hidden_dim)\n",
        "\n",
        "    self.scale   = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
        "    self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "  def forward(self, query, key, value, mask=None):\n",
        "    batch_size = query.shape[0]\n",
        "    # query: [batch_size, query_len, hidden_dim]\n",
        "    # key  : [batch_size, key_len, hidden_dim]\n",
        "    # value: [batch_size, value_len, hidden_dim]\n",
        "\n",
        "    Q = self.fc_query(query)\n",
        "    K = self.fc_key(key)\n",
        "    V = self.fc_value(value)\n",
        "    # Q: [batch_size, query_len, hidden_dim]\n",
        "    # K: [batch_size, key_len, hidden_dim]\n",
        "    # V: [batch_size, value_len, hidden_dim]\n",
        "\n",
        "    # hidden_dim to n_heads * head_dim\n",
        "    Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "    K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "    V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "    # Q: [batch_size, n_heads, query_len, head_dim]\n",
        "    # K: [batch_size, n_heads, key_len, head_dim]\n",
        "    # V: [batch_size, n_heads, value_len, head_dim]\n",
        "\n",
        "    # attention energies, (Q*K^T/n)\n",
        "    energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
        "    # energy: [batch_size, n_heads, query_len, key_len]\n",
        "\n",
        "    # masking\n",
        "    if mask is not None:\n",
        "      energy = energy.masked_fill(mask==0, -1e10)\n",
        "\n",
        "    # attention score, softmax(Q*K^T/n)\n",
        "    attention = torch.softmax(energy, dim=-1)\n",
        "    # attention: [batch_size, n_heads, query_len, key_len]\n",
        "\n",
        "    # softmax(Q*K^T/n)*V\n",
        "    x = torch.matmul(self.dropout(attention), V)\n",
        "    # x: [batch_size, n_heads, query_len, head_dim]\n",
        "\n",
        "    x = x.permute(0, 2, 1, 3).contiguous()\n",
        "    x = x.view(batch_size, -1, self.hidden_dim)\n",
        "    # x: [batch_size, query_len, hidden_dim]\n",
        "    x = self.fc_o(x)\n",
        "    return x, attention\n",
        "\n",
        "\n",
        "class PositionwiseFeedforwardLayer(nn.Module):\n",
        "  def __init__(self, hidden_dim, pf_dim, dropout_ratio):\n",
        "    super().__init__()\n",
        "    self.fc_1 = nn.Linear(hidden_dim, pf_dim)\n",
        "    self.fc_2 = nn.Linear(pf_dim, hidden_dim)\n",
        "    self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # x: [batch_size, seq_len, hidden_dim]\n",
        "\n",
        "    x = self.dropout(torch.relu(self.fc_1(x)))\n",
        "    # x: [batch_size, seq_len, pf_dim]\n",
        "\n",
        "    x = self.fc_2(x)\n",
        "    # x: [batch_size, seq_len, hidden_dim]\n",
        "    return x"
      ],
      "metadata": {
        "id": "QddSV6nPNFvl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### transformer encoder"
      ],
      "metadata": {
        "id": "6wIonehfEbtZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "  def __init__(self, hidden_dim, n_heads, pf_dim, dropout_ratio, device):\n",
        "    super().__init__()\n",
        "    self.self_attn_layer_norm = nn.LayerNorm(hidden_dim)\n",
        "    self.ff_layer_norm        = nn.LayerNorm(hidden_dim)\n",
        "\n",
        "    self.self_attention           = MultiHeadAttentionLayer(hidden_dim, n_heads, dropout_ratio, device)\n",
        "    self.positionwise_feedforward = PositionwiseFeedforwardLayer(hidden_dim, pf_dim, dropout_ratio)\n",
        "    self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "  def forward(self, src, src_mask):\n",
        "    # src     : [batch_size, src_len, hidden_dim]\n",
        "    # src_mask: [batch_size, src_len]\n",
        "\n",
        "    # self attention\n",
        "    _src, _ = self.self_attention(src, src, src, src_mask)\n",
        "\n",
        "    # residual connection & layer norm\n",
        "    src = self.self_attn_layer_norm(src + self.dropout(_src))\n",
        "\n",
        "    # position-wise feed forward\n",
        "    _src = self.positionwise_feedforward(src)\n",
        "\n",
        "    # residual connection & layer norm\n",
        "    src = self.ff_layer_norm(src + self.dropout(_src))\n",
        "    return src\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, n_layers, n_heads, pf_dim, dropout_ratio, device, max_length=100):\n",
        "    super().__init__()\n",
        "    self.device = device\n",
        "    self.tok_embedding = nn.Embedding(input_dim, hidden_dim)\n",
        "    self.pos_embedding = nn.Embedding(max_length, hidden_dim)\n",
        "    self.layers  = nn.ModuleList([EncoderLayer(hidden_dim, n_heads, pf_dim, dropout_ratio, device)\n",
        "                                  for _ in range(n_layers)])\n",
        "    \n",
        "    self.scale   = torch.sqrt(torch.FloatTensor([hidden_dim])).to(device)\n",
        "    self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "  def forward(self, src, src_mask):\n",
        "    # src     : [batch_size, src_len]\n",
        "    # src_mask: [batch_size, src_len]\n",
        "    \n",
        "    batch_size = src.shape[0]  # number of sentences\n",
        "    src_len    = src.shape[1]  # longest sentence's length\n",
        "\n",
        "    pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "    # pos: [batch_size, src_len]\n",
        "\n",
        "    # token embedding + position embedding\n",
        "    src = self.dropout((self.tok_embedding(src) * self.scale) + self.pos_embedding(pos))\n",
        "\n",
        "    # forward for all layers\n",
        "    for layer in self.layers:\n",
        "      src = layer(src, src_mask)\n",
        "    # src: [batch_size, src_len, hidden_dim]\n",
        "    return src"
      ],
      "metadata": {
        "id": "doh5YsYZhdTC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### transformer decoder"
      ],
      "metadata": {
        "id": "9nssrEPAEdaJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "  def __init__(self, hidden_dim, n_heads, pf_dim, dropout_ratio, device):\n",
        "    super().__init__()\n",
        "    self.self_attn_layer_norm  = nn.LayerNorm(hidden_dim)\n",
        "    self.enc_attn_layer_norm   = nn.LayerNorm(hidden_dim)\n",
        "    self.ff_layer_norm         = nn.LayerNorm(hidden_dim)\n",
        "\n",
        "    self.self_attention           = MultiHeadAttentionLayer(hidden_dim, n_heads, dropout_ratio, device)\n",
        "    self.encoder_attention        = MultiHeadAttentionLayer(hidden_dim, n_heads, dropout_ratio, device)\n",
        "    self.positionwise_feedforward = PositionwiseFeedforwardLayer(hidden_dim, pf_dim, dropout_ratio)\n",
        "    self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "  # attention for encoding's output\n",
        "  def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "    # trg     : [batch_size, trg_len, hidden_dim]\n",
        "    # enc_src : [batch_size, src_len, hidden_dim]\n",
        "    # trg_mask: [batch_size, trg_len]\n",
        "    # src_mask: [batch_size, src_len]\n",
        "\n",
        "    # self attention\n",
        "    _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\n",
        "\n",
        "    # residual connection & layer norm\n",
        "    trg = self.self_attn_layer_norm(trg + self.dropout(_trg))\n",
        "\n",
        "    # encoder attention\n",
        "    _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\n",
        "\n",
        "    # residual connection & layer_norm\n",
        "    trg = self.enc_attn_layer_norm(trg + self.dropout(_trg)) \n",
        "\n",
        "    # positionwise feed forward\n",
        "    _trg = self.positionwise_feedforward(trg)\n",
        "\n",
        "    # residual connection & layer norm\n",
        "    trg = self.ff_layer_norm(trg + self.dropout(_trg))\n",
        "\n",
        "    # trg      : [batch_size, trg_len, hidden_dim]\n",
        "    # attention: [batch_size, n_heads, trg_len, src_len]\n",
        "    return trg, attention\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self, output_dim, hidden_dim, n_layers, n_heads, pf_dim, dropout_ratio, device, max_length=100):\n",
        "    super().__init__()\n",
        "    self.device = device\n",
        "    self.tok_embedding = nn.Embedding(output_dim, hidden_dim)\n",
        "    self.pos_embedding = nn.Embedding(max_length, hidden_dim)\n",
        "    self.layers = nn.ModuleList([DecoderLayer(hidden_dim, n_heads, pf_dim, dropout_ratio, device)\n",
        "                                 for _ in range(n_layers)])\n",
        "\n",
        "    self.fc_out  = nn.Linear(hidden_dim, output_dim)\n",
        "    self.scale   = torch.sqrt(torch.FloatTensor([hidden_dim])).to(device)\n",
        "    self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "  def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "    # trg     : [batch_size, trg_len]\n",
        "    # enc_src : [batch_size, src_len, hidden_dim]\n",
        "    # trg_mask: [batch_size, trg_len]\n",
        "    # src_mask: [batch_size, src_len]\n",
        "\n",
        "    batch_size = trg.shape[0]\n",
        "    trg_len    = trg.shape[1]\n",
        "\n",
        "    pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "    # pos: [batch_size, trg_len]\n",
        "\n",
        "    trg = self.dropout((self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))\n",
        "    # trg: [batch_size, trg_len, hidden_dim]\n",
        "\n",
        "    for layer in self.layers:\n",
        "      trg, attention = layer(trg, enc_src, trg_mask, src_mask)\n",
        "    # trg      : [batch_size, trg_len, hidden_dim]\n",
        "    # attention: [batch_size, n_heads, trg_len, src_len]\n",
        "\n",
        "    output = self.fc_out(trg)\n",
        "    # output: [batch_size, trg_len, output_dim]\n",
        "    return output, attention"
      ],
      "metadata": {
        "id": "2scO308hSJuu"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### transformer"
      ],
      "metadata": {
        "id": "13aUNYgHEgTq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn.Module):\n",
        "  def __init__(self, encoder, decoder, pad_idx, device):\n",
        "    super().__init__()\n",
        "    self.device = device\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.src_pad_idx, self.trg_pad_idx = pad_idx, pad_idx\n",
        "\n",
        "  # masking for <pad> token\n",
        "  def make_src_mask(self, src):\n",
        "    # src: [batch_size, src_len]\n",
        "\n",
        "    src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "    # src_mask: [batch_size, 1, 1, src_len]\n",
        "    return src_mask\n",
        "\n",
        "  # masking for next tokens in target sentence\n",
        "  def make_trg_mask(self, trg):\n",
        "    # trg: [batch_size, trg_len]\n",
        "\n",
        "    trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "    # trg_pad_mask: [batch_size, 1, 1, trg_len]\n",
        "\n",
        "    trg_len = trg.shape[1]\n",
        "    trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device=self.device)).bool()\n",
        "    # trg_sub_mask: [trg_len, trg_len]\n",
        "\n",
        "    trg_mask = trg_pad_mask & trg_sub_mask\n",
        "    # trg_mask: [batch_size, 1, trg_len, trg_len]\n",
        "    return trg_mask\n",
        "\n",
        "  def forward(self, src, trg):\n",
        "    # src: [batch_size, src_len]\n",
        "    # trg: [batch_size, trg_len]\n",
        "\n",
        "    src_mask = self.make_src_mask(src)\n",
        "    trg_mask = self.make_trg_mask(trg)\n",
        "    # src_mask: [batch_size, 1, 1, src_len]\n",
        "    # trg_mask: [batch_size, 1, trg_len, trg_len]\n",
        "\n",
        "    enc_src = self.encoder(src, src_mask)\n",
        "    # enc_src: [batch_size, src_len, hidden_dim]\n",
        "\n",
        "    output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
        "    # output   : [batch_size, trg_len, output_dim]\n",
        "    # attention: [batch_size, n_heads, trg_len, src_len]\n",
        "    return output, attention"
      ],
      "metadata": {
        "id": "EWMM1IfVWoTH"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyper parameters\n",
        "INPUT_DIM, OUTPUT_DIM = len(en_vocab), len(de_vocab)\n",
        "HIDDEN_DIM = 256\n",
        "LAYERS     = 3\n",
        "HEADS      = 8\n",
        "PF_DIM     = 512\n",
        "DROPOUT    = 0.1"
      ],
      "metadata": {
        "id": "2zNIAxunPfNe"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Encoder(INPUT_DIM, HIDDEN_DIM, LAYERS, HEADS, PF_DIM, DROPOUT, device)\n",
        "decoder = Decoder(OUTPUT_DIM, HIDDEN_DIM, LAYERS, HEADS, PF_DIM, DROPOUT, device)\n",
        "model   = Transformer(encoder, decoder, preprocessor.pad_token_id, device)\n",
        "\n",
        "def count_parameters(model):\n",
        "  return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters.\\n')\n",
        "\n",
        "def initialize_weights(model):\n",
        "  for p in model.parameters():\n",
        "    if p.dim() > 1: nn.init.xavier_uniform_(p)\n",
        "\n",
        "model.apply(initialize_weights)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpe3_p9FFn9D",
        "outputId": "f6973f0d-1456-4de7-f281-0c6e3c9f9cad"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 9,700,942 trainable parameters.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# using adam optimizer\n",
        "LR_RATE   = 0.0005\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR_RATE)\n",
        "\n",
        "# define loss function, ignore for padding value\n",
        "loss_fn = nn.CrossEntropyLoss(ignore_index=preprocessor.pad_token_id)"
      ],
      "metadata": {
        "id": "igxnW68xGW-9"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### training"
      ],
      "metadata": {
        "id": "eQhVrr9KEqTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, iterator, optimizer, loss_fn, clip):\n",
        "  model.train()\n",
        "  epoch_loss = 0\n",
        "\n",
        "  for i, batch in enumerate(iterator):\n",
        "    src, trg = batch[0], batch[1]\n",
        "    \n",
        "    optimizer.zero_grad()  # make gradients zero before backpropagation\n",
        "\n",
        "    output, _ = model(src, trg[:,:-1])        # ignore for target's <eos>\n",
        "    # output: [batch_size, trg_len-1, output_dim]\n",
        "    # trg   : [batch_size, trg_len]\n",
        "\n",
        "    output_dim = output.shape[-1]\n",
        "    output = output.contiguous().view(-1, output_dim)\n",
        "    trg    = trg[:,1:].contiguous().view(-1)  # ignore for target's <sos>\n",
        "    # output: [batch_size * trg_len-1, output_dim]\n",
        "    # trg   : [batch_size * trg_len-1]\n",
        "\n",
        "    loss = loss_fn(output, trg)\n",
        "    epoch_loss += loss.item()\n",
        "\n",
        "    loss.backward()                                           # compute gradient\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), clip)  # gradient clipping\n",
        "    optimizer.step()                                          # update parameters\n",
        "  return epoch_loss / len(iterator)\n",
        "\n",
        "def evaluate(model, iterator, loss_fn):\n",
        "  model.eval()\n",
        "  epoch_loss = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for i, batch in enumerate(iterator):\n",
        "      src, trg = batch[0], batch[1]\n",
        "\n",
        "      output, _ = model(src, trg[:,:-1])        # ignore for target's <eos>\n",
        "      # output: [batch_size, trg_len-1, output_dim]\n",
        "      # trg   : [batch_size, trg_len]\n",
        "\n",
        "      output_dim = output.shape[-1]\n",
        "      output = output.contiguous().view(-1, output_dim)\n",
        "      trg    = trg[:,1:].contiguous().view(-1)  # ignore for target's <sos>\n",
        "      # output: [batch_size * trg_len-1, output_dim]\n",
        "      # trg   : [batch_size * trg_len-1]\n",
        "\n",
        "      loss = loss_fn(output, trg)\n",
        "      epoch_loss += loss.item()\n",
        "  return epoch_loss / len(iterator)\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "  elapsed_time = end_time - start_time\n",
        "  elapsed_mins = int(elapsed_time / 60)\n",
        "  elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "  return elapsed_mins, elapsed_secs"
      ],
      "metadata": {
        "id": "IAzUAjWwIp3z"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "EPOCHS = 10\n",
        "CLIP   = 1\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start_time = time.time()\n",
        "\n",
        "  train_loss = train(model, train_loader, optimizer, loss_fn, CLIP)\n",
        "  valid_loss = evaluate(model, valid_loader, loss_fn)\n",
        "\n",
        "  end_time = time.time()\n",
        "  epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "  if valid_loss < best_valid_loss:\n",
        "    best_valid_loss = valid_loss\n",
        "    torch.save(model.state_dict(), 'transformer_en_to_de.pt')\n",
        "\n",
        "  print(f'Epoch: {epoch + 1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "  print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):.3f}')\n",
        "  print(f'\\tValidation Loss: {valid_loss:.3f} | Validation PPL: {math.exp(valid_loss):.3f}')\n",
        "  print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZNjQRGkP0Kh",
        "outputId": "73518d89-74aa-4cc0-bde3-1c30e027a9d9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Time: 0m 19s\n",
            "\tTrain Loss: 3.977 | Train PPL: 53.343\n",
            "\tValidation Loss: 2.898 | Validation PPL: 18.131\n",
            "\n",
            "\n",
            "Epoch: 02 | Time: 0m 17s\n",
            "\tTrain Loss: 2.592 | Train PPL: 13.352\n",
            "\tValidation Loss: 2.208 | Validation PPL: 9.099\n",
            "\n",
            "\n",
            "Epoch: 03 | Time: 0m 16s\n",
            "\tTrain Loss: 2.010 | Train PPL: 7.464\n",
            "\tValidation Loss: 1.879 | Validation PPL: 6.550\n",
            "\n",
            "\n",
            "Epoch: 04 | Time: 0m 16s\n",
            "\tTrain Loss: 1.663 | Train PPL: 5.276\n",
            "\tValidation Loss: 1.705 | Validation PPL: 5.500\n",
            "\n",
            "\n",
            "Epoch: 05 | Time: 0m 16s\n",
            "\tTrain Loss: 1.418 | Train PPL: 4.129\n",
            "\tValidation Loss: 1.599 | Validation PPL: 4.950\n",
            "\n",
            "\n",
            "Epoch: 06 | Time: 0m 17s\n",
            "\tTrain Loss: 1.230 | Train PPL: 3.422\n",
            "\tValidation Loss: 1.564 | Validation PPL: 4.777\n",
            "\n",
            "\n",
            "Epoch: 07 | Time: 0m 16s\n",
            "\tTrain Loss: 1.081 | Train PPL: 2.949\n",
            "\tValidation Loss: 1.549 | Validation PPL: 4.706\n",
            "\n",
            "\n",
            "Epoch: 08 | Time: 0m 16s\n",
            "\tTrain Loss: 0.966 | Train PPL: 2.626\n",
            "\tValidation Loss: 1.593 | Validation PPL: 4.919\n",
            "\n",
            "\n",
            "Epoch: 09 | Time: 0m 16s\n",
            "\tTrain Loss: 0.871 | Train PPL: 2.390\n",
            "\tValidation Loss: 1.609 | Validation PPL: 4.998\n",
            "\n",
            "\n",
            "Epoch: 10 | Time: 0m 16s\n",
            "\tTrain Loss: 0.790 | Train PPL: 2.203\n",
            "\tValidation Loss: 1.614 | Validation PPL: 5.022\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download saved model\n",
        "from google.colab import files\n",
        "files.download('transformer_en_to_de.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "rGWFxBfYjmmx",
        "outputId": "7ee00c98-1759-4da5-ccbe-ccd28e745abd"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2174568a-bc88-4391-8012-245c2e7dfaa9\", \"transformer_en_to_de.pt\", 38853881)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### testing"
      ],
      "metadata": {
        "id": "iL3-6GxGEuBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load saved model\n",
        "model.load_state_dict(torch.load('./transformer_en_to_de.pt'))\n",
        "\n",
        "# test\n",
        "test_loss = evaluate(model, test_loader, loss_fn)\n",
        "print(f'Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7usX9yPjy1O",
        "outputId": "2501efd4-a57f-4c1b-f5a5-fcb3f5bd441b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 1.614 | Test PPL: 5.023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# translation using my model\n",
        "def translate_sentence(sentence, preprocessor, model, device, max_len=50):\n",
        "  model.eval()\n",
        "\n",
        "  # make source indices\n",
        "  src_indices = preprocessor.src_encode(sentence)\n",
        "  src_indices = [preprocessor.sos_token_id] + src_indices + [preprocessor.eos_token_id]\n",
        "\n",
        "  # using encoder\n",
        "  src_tensor = torch.LongTensor(src_indices).unsqueeze(0).to(device)\n",
        "  src_mask   = model.make_src_mask(src_tensor)\n",
        "  with torch.no_grad():\n",
        "    enc_src = model.encoder(src_tensor, src_mask)\n",
        "\n",
        "  # using decoder, make translated target indices\n",
        "  trg_indices = [preprocessor.sos_token_id]            # has <sos> token\n",
        "  for i in range(max_len):\n",
        "    trg_tensor = torch.LongTensor(trg_indices).unsqueeze(0).to(device)\n",
        "    trg_mask   = model.make_trg_mask(trg_tensor)\n",
        "    with torch.no_grad():\n",
        "      output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\n",
        "\n",
        "    pred_token = output.argmax(2)[:,-1].item()\n",
        "    if pred_token == preprocessor.eos_token_id: break  # break when <eos> token\n",
        "    else: trg_indices.append(pred_token)\n",
        "\n",
        "  # convert indices to words\n",
        "  trg_tokens = [preprocessor.tgt_id2token[id] for id in trg_indices]\n",
        "  return trg_tokens[1:], attention                     # remove <sos> token"
      ],
      "metadata": {
        "id": "-G-QCacMkLUO"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, batch in enumerate(test_dataset):\n",
        "  if i == 10:\n",
        "    src, tgt = batch[0], batch[1]\n",
        "    break\n",
        "src = preprocessor.src_decode(src)\n",
        "tgt = preprocessor.tgt_decode(tgt)\n",
        "print('original en sentence:')\n",
        "print(f'\\t{src}')\n",
        "print('original de sentence:')\n",
        "print(f'\\t{tgt}')\n",
        "\n",
        "translation, _ = translate_sentence(src, preprocessor, model, device)\n",
        "translation = ' '.join(translation)\n",
        "print('translated de sentence:')\n",
        "print(f'\\t{translation}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vd2yQwDYVRgx",
        "outputId": "616d474a-5b75-4e91-c695-d559a85af9ce"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original en sentence:\n",
            "\tA mother and her young song enjoying a beautiful day outside .\n",
            "original de sentence:\n",
            "\tEine Mutter und ihr kleiner Sohn genießen einen schönen Tag im Freien .\n",
            "translated de sentence:\n",
            "\tEine Mutter und ihre Mutter genießen einen schönen Tag im Freien .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for bleu score\n",
        "!pip install torchtext==0.6.0"
      ],
      "metadata": {
        "id": "dbO9T5CDKuS3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "outputId": "1be32a3e-1824-4bbf-8e46-c8bdeff6ff7a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchtext==0.6.0\n",
            "  Downloading torchtext-0.6.0-py3-none-any.whl (64 kB)\n",
            "\u001b[K     |████████████████████████████████| 64 kB 2.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.21.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (2.23.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.12.1+cu113)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 9.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (2.10)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchtext==0.6.0) (4.1.1)\n",
            "Installing collected packages: sentencepiece, torchtext\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.13.1\n",
            "    Uninstalling torchtext-0.13.1:\n",
            "      Successfully uninstalled torchtext-0.13.1\n",
            "Successfully installed sentencepiece-0.1.97 torchtext-0.6.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torchtext"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.data.metrics import bleu_score\n",
        "\n",
        "def show_bleu(data, preprocessor, model, device, max_len=50):\n",
        "  trgs, pred_trgs = [], []\n",
        "  for i in range(len(data)):\n",
        "    # original target\n",
        "    src, trg = data[i][0], data[i][1]\n",
        "    src = preprocessor.src_decode(src)\n",
        "    trg = preprocessor.tgt_decode(trg).split(' ')\n",
        "    trgs.append([trg])\n",
        "\n",
        "    # predicted target\n",
        "    pred_trg, _ = translate_sentence(src, preprocessor, model, device, max_len)\n",
        "    pred_trg = pred_trg[:-1]\n",
        "    pred_trgs.append(pred_trg)\n",
        "\n",
        "    if (i + 1)%100 == 0:\n",
        "      print(f\"[{i+1}/{len(data)}]\")\n",
        "      print(f\"정답: {trg}\")\n",
        "      print(f\"예측: {pred_trg}\\n\")\n",
        "\n",
        "  bleu = bleu_score(pred_trgs, trgs, max_n=4, weights=[0.25, 0.25, 0.25, 0.25])\n",
        "  print(f'Total BLEU Score = {bleu*100:.2f}')\n",
        "\n",
        "  bleu1_score = bleu_score(pred_trgs, trgs, max_n=4, weights=[1, 0, 0, 0])\n",
        "  bleu2_score = bleu_score(pred_trgs, trgs, max_n=4, weights=[0, 1, 0, 0])\n",
        "  bleu3_score = bleu_score(pred_trgs, trgs, max_n=4, weights=[0, 0, 1, 0])\n",
        "  bleu4_score = bleu_score(pred_trgs, trgs, max_n=4, weights=[0, 0, 0, 1])\n",
        "  print(f'BLEU1 score = {bleu1_score}') \n",
        "  print(f'BLEU2 score = {bleu2_score}') \n",
        "  print(f'BLEU3 score = {bleu3_score}') \n",
        "  print(f'BLEU4 score = {bleu4_score}') \n",
        "\n",
        "show_bleu(test_dataset, preprocessor, model, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vjjmi4DGo-Tt",
        "outputId": "962b4a5b-d589-4146-b3f3-df6a2d26f23b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100/1000]\n",
            "정답: ['Ein', 'kleiner', 'Junge', 'im', 'Fußballdress', 'hält', 'die', 'Hände', '<unk>', 'Gesicht', 'und', 'weint', '.']\n",
            "예측: ['Ein', 'kleiner', 'Junge', 'in', 'Uniform', 'schreit', 'in', 'einen', 'Fußball', 'in', 'seiner', '<unk>']\n",
            "\n",
            "[200/1000]\n",
            "정답: ['Ein', 'Mann', 'macht', 'Werbung', 'mit', 'einem', 'riesigen', 'Schild', ',', 'das', 'auf', 'sein', 'Fahrrad', 'gebunden', 'ist', '.']\n",
            "예측: ['Ein', 'Mann', '<unk>', 'mit', 'einem', 'riesigen', 'Schild', 'auf', 'seinem', 'Fahrrad']\n",
            "\n",
            "[300/1000]\n",
            "정답: ['Eine', 'Gruppe', 'junger', 'Menschen', 'trinkt', '<unk>', 'in', 'einem', '<unk>', '<unk>', '.']\n",
            "예측: ['Eine', 'Gruppe', 'junger', 'Japaner', 'machen', 'in', 'einer', '<unk>']\n",
            "\n",
            "[400/1000]\n",
            "정답: ['Ein', 'lächelnder', 'Junge', 'spielt', 'im', 'Laub', 'mit', 'den', 'Enten', '.']\n",
            "예측: ['Ein', 'lächelnder', 'kleiner', 'Junge', 'spielt', 'im', 'Laub', 'zwischen', 'Reihen', 'von', 'sich']\n",
            "\n",
            "[500/1000]\n",
            "정답: ['Eine', 'Frau', 'steht', 'auf', 'einem', 'grünen', 'Feld', ',', 'hält', 'einen', 'weißen', 'Hund', 'und', 'zeigt', 'auf', 'einen', 'braunen', 'Hund', '.']\n",
            "예측: ['Eine', 'Frau', 'steht', 'auf', 'einem', 'grünen', 'Feld', 'und', 'hält', 'einen', 'Hund', 'an', 'einem', 'weißen', 'Hund', 'fest']\n",
            "\n",
            "[600/1000]\n",
            "정답: ['Ein', 'Typ', 'in', 'einem', 'gelben', 'Outfit', 'steht', 'hinter', 'dem', 'Mikrofon', 'in', 'einem', 'Zelt', '.']\n",
            "예측: ['Ein', 'Mann', 'in', 'einem', 'gelben', 'Outfit', 'steht', 'hinter', 'einem', 'Mikrofon', 'und', 'steht', 'auf', 'einem', 'Mikrofon']\n",
            "\n",
            "[700/1000]\n",
            "정답: ['Zwei', 'Motocrossfahrer', 'in', 'voller', 'Schutzkleidung', ',', 'einer', 'von', 'ihnen', 'ist', 'nach', 'einem', 'Sprung', 'in', 'der', 'Luft', ',', 'der', 'andere', 'blickt', 'auf', 'sein', 'Motorrad', 'hinunter', '.']\n",
            "예측: ['Zwei', 'Motocross-Fahrer', 'mit', 'Schutzkleidung', ',', 'die', 'nach', 'oben', 'auf', 'einem', 'Motorrad', 'fahren', ',', 'während', 'er', 'sich', 'in', 'der', 'Luft', 'auf', 'einem', 'Motorrad', 'springt']\n",
            "\n",
            "[800/1000]\n",
            "정답: ['Ein', 'Mann', 'sitzt', 'auf', 'einer', 'Plattform', 'mit', 'Rädern', 'und', 'wird', 'an', 'einem', 'Loch', '<unk>', '.']\n",
            "예측: ['Ein', 'Mann', 'sitzt', 'auf', 'einem', 'Bahnsteig', 'mit', '<unk>', 'von', 'einem', '<unk>']\n",
            "\n",
            "[900/1000]\n",
            "정답: ['Eine', 'Person', 'in', 'Blau', 'wirft', 'auf', 'einer', 'Bowlingbahn', 'als', '<unk>', 'ihre', 'Kugel', '.']\n",
            "예측: ['Eine', 'Person', 'in', 'Blau', 'wird', 'von', 'der', 'anderen', 'Person', 'auf', 'der', 'Bowlingbahn', 'geworfen']\n",
            "\n",
            "[1000/1000]\n",
            "정답: ['Ein', 'Mädchen', 'an', 'einer', 'Küste', 'mit', 'einem', 'Berg', 'im', 'Hintergrund', '.']\n",
            "예측: ['Ein', 'Mädchen', 'am', 'Strand', 'mit', 'einem', 'Berghang', 'in', 'die', 'Ferne', 'ist']\n",
            "\n",
            "Total BLEU Score = 28.06\n",
            "BLEU1 score = 0.5697453213614576\n",
            "BLEU2 score = 0.3437067717599644\n",
            "BLEU3 score = 0.22297719940471195\n",
            "BLEU4 score = 0.1419150741270214\n"
          ]
        }
      ]
    }
  ]
}