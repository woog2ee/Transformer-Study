{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### set device and data"
      ],
      "metadata": {
        "id": "5hXkBJT2DsVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'using device: {DEVICE}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfEgZTu7hGWI",
        "outputId": "54ffde18-b55a-4d97-90b9-eed5d64f11b8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def file2list(file):\n",
        "    lst = []\n",
        "    for line in open(f'./{file}', 'r', encoding='utf-8-sig'):\n",
        "      line = line.replace('\\n', '')\n",
        "      lst.append(line)\n",
        "    return lst\n",
        "\n",
        "# train, valid, test texts\n",
        "en_train_lst = file2list('train.en')\n",
        "en_valid_lst = file2list('val.en')\n",
        "en_test_lst  = file2list('test.en')\n",
        "print(f'en data: {len(en_train_lst), len(en_valid_lst), len(en_test_lst)}')\n",
        "\n",
        "de_train_lst = file2list('train.de')\n",
        "de_valid_lst = file2list('val.de')\n",
        "de_test_lst  = file2list('test.de')\n",
        "print(f'de data: {len(de_train_lst), len(de_valid_lst), len(de_test_lst)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbM-LRoP2uoA",
        "outputId": "7e2ba247-5a0a-462b-c651-0a40758004f2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "en data: (29001, 1015, 1000)\n",
            "de data: (29001, 1015, 1000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### build vocabularies"
      ],
      "metadata": {
        "id": "OqK109CLDzBT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# using spacy tokenizer\n",
        "!python -m spacy download en_core_web_sm\n",
        "!python -m spacy download de_core_news_sm"
      ],
      "metadata": {
        "id": "-ZegqCCcNqMY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dfb6b73-cf3e-484a-9f1a-a1f56649dce3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-sm==3.4.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.4.0/en_core_web_sm-3.4.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8 MB 26.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-sm==3.4.0) (3.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.11.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.9.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.21.6)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.4.4)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (8.1.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (4.64.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (21.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.10)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.6.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.0.8)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.23.0)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.0.3)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.4.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (57.4.0)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (4.1.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.8)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.10.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (5.2.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.10)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.0.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.7.8)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting de-core-news-sm==3.4.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.4.0/de_core_news_sm-3.4.0-py3-none-any.whl (14.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.6 MB 26.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from de-core-news-sm==3.4.0) (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.21.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.10.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.0.8)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.0.10)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.0.3)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.6.2)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (4.1.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.0.7)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (4.64.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.0.8)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.4.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.0.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.23.0)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (8.1.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (21.3)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.4.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (57.4.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.11.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.9.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (5.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.7.8)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.0.2)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.0.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('de_core_news_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "# using spacy tokenizer\n",
        "en_tokenizer = get_tokenizer(tokenizer='spacy', language='en_core_web_sm')\n",
        "de_tokenizer = get_tokenizer(tokenizer='spacy', language='de_core_news_sm')\n",
        "\n",
        "# vocabulary for training texts\n",
        "en_vocab = build_vocab_from_iterator(map(en_tokenizer, [text for text in en_train_lst]),\n",
        "                                     min_freq=2,\n",
        "                                     specials=['<unk>','<sos>','<eos>','<pad>'],\n",
        "                                     special_first=True)\n",
        "de_vocab = build_vocab_from_iterator(map(de_tokenizer, [text for text in de_train_lst]),\n",
        "                                     min_freq=2,\n",
        "                                     specials=['<unk>','<sos>','<eos>','<pad>'],\n",
        "                                     special_first=True)\n",
        "print(f'en vocab size: {len(en_vocab)}')\n",
        "print(f'de vocab size: {len(de_vocab)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXcQJnCbN1H0",
        "outputId": "1cba156d-5545-464a-fb26-0ba56ac54528"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "en vocab size: 6191\n",
            "de vocab size: 8014\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### make preprocessor for encode & decode texts"
      ],
      "metadata": {
        "id": "PEAj3JF8D8bX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Preprocessor:\n",
        "  unk_token_id = 0\n",
        "  sos_token_id = 1\n",
        "  eos_token_id = 2\n",
        "  pad_token_id = 3\n",
        "\n",
        "  def __init__(self, src_tokenizer, tgt_tokenizer, src_vocab, tgt_vocab):\n",
        "    self.src_tokenizer = src_tokenizer\n",
        "    self.tgt_tokenizer = tgt_tokenizer\n",
        "\n",
        "    # token -> id\n",
        "    self.src_token2id = src_vocab.get_stoi()\n",
        "    self.tgt_token2id = tgt_vocab.get_stoi()\n",
        "    # id -> token\n",
        "    self.src_id2token = src_vocab.get_itos()\n",
        "    self.tgt_id2token = tgt_vocab.get_itos()\n",
        "\n",
        "  # encode token -> id for source sentence\n",
        "  def src_encode(self, text):\n",
        "    if type(text) == list: text = ' '.join(text)\n",
        "    tokenized = self.src_tokenizer(text)\n",
        "    encoded   = [self.src_token2id.get(token, self.src_token2id['<unk>']) for token in tokenized]\n",
        "    return encoded\n",
        "\n",
        "  # encode token -> id, attach <sos> and <eos> for target sentence\n",
        "  def tgt_encode(self, text):\n",
        "    if type(text) == list: text = ' '.join(text)\n",
        "    tokenized = self.tgt_tokenizer(text)\n",
        "    encoded   = [self.tgt_token2id['<sos>']] \\\n",
        "    + [self.tgt_token2id.get(token, self.tgt_token2id['<unk>']) for token in tokenized] \\\n",
        "    + [self.tgt_token2id['<eos>']]\n",
        "    return encoded\n",
        "\n",
        "  # decode source sentence\n",
        "  def src_decode(self, ids):\n",
        "    decoded = list(map(lambda x: self.src_id2token[x], ids))\n",
        "    return ' '.join(decoded)\n",
        "\n",
        "  # decode target sentence\n",
        "  def tgt_decode(self, ids):\n",
        "    decoded = list(map(lambda x: self.tgt_id2token[x], ids))[1:-1]\n",
        "    return ' '.join(decoded)\n",
        "\n",
        "preprocessor = Preprocessor(en_tokenizer, de_tokenizer, en_vocab, de_vocab)"
      ],
      "metadata": {
        "id": "_sxputetzNrJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### make custom dataset, data loader"
      ],
      "metadata": {
        "id": "uwID8j0DEIGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data.dataset import Dataset\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, en_lst, de_lst, preprocessor):\n",
        "    self.en_lst = en_lst\n",
        "    self.de_lst = de_lst\n",
        "    assert len(self.en_lst) == len(self.de_lst)\n",
        "\n",
        "    self.preprocessor = preprocessor\n",
        "    self.dataset      = self.make_dataset()\n",
        "\n",
        "  # make (en, de) sentence pair dataset\n",
        "  def make_dataset(self):\n",
        "    dataset = [(self.preprocessor.src_encode(en), self.preprocessor.tgt_encode(de))\n",
        "               for en, de in zip(self.en_lst, self.de_lst)\n",
        "               if len(en) > 0 and len(de) > 0]\n",
        "    return dataset\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.dataset[idx]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.dataset)\n",
        "\n",
        "train_dataset = CustomDataset(en_train_lst, de_train_lst, preprocessor)\n",
        "valid_dataset = CustomDataset(en_valid_lst, de_valid_lst, preprocessor)\n",
        "test_dataset  = CustomDataset(en_test_lst, de_test_lst, preprocessor)\n",
        "print(f'dataset size: {len(train_dataset), len(valid_dataset), len(test_dataset)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BobpKq6N7YeR",
        "outputId": "1b35e4a6-26f5-42fc-b77b-5551137fd76d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset size: (29000, 1014, 1000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# sequence padding in batch\n",
        "def collate_fn(batch_samples):\n",
        "  pad_token_id = preprocessor.pad_token_id\n",
        "  src_sent = pad_sequence([torch.tensor(src) for src, _ in batch_samples],\n",
        "                          batch_first=True,\n",
        "                          padding_value=pad_token_id)\n",
        "  tgt_sent = pad_sequence([torch.tensor(tgt) for _, tgt in batch_samples],\n",
        "                          batch_first=True,\n",
        "                          padding_value=pad_token_id)\n",
        "  return src_sent.to(DEVICE), tgt_sent.to(DEVICE)\n",
        "\n",
        "# composing batch to match similar lengths of sequences\n",
        "def batch_sampling(sequence_lengths, BATCH_SIZE):\n",
        "  seq_lens = [(i, seq_len, tgt_len) for i, (seq_len, tgt_len) in enumerate(sequence_lengths)]\n",
        "  seq_lens = sorted(seq_lens, key=lambda x: x[1])\n",
        "  seq_lens = [sample[0] for sample in seq_lens]\n",
        "\n",
        "  sample_indices = [seq_lens[i:i+BATCH_SIZE] for i in range(0, len(seq_lens), BATCH_SIZE)]\n",
        "  random.shuffle(sample_indices)\n",
        "  return sample_indices\n",
        "\n",
        "# make dataloader using sequence padding & composing batch\n",
        "def make_loader(dataset, BATCH_SIZE):\n",
        "  sequence_lengths = list(map(lambda x: (len(x[0]), len(x[1])), dataset))\n",
        "  batch_sampler = batch_sampling(sequence_lengths, BATCH_SIZE)\n",
        "  loader = DataLoader(dataset,\n",
        "                      collate_fn=collate_fn,\n",
        "                      batch_sampler=batch_sampler)\n",
        "  return loader\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "train_loader = make_loader(train_dataset, BATCH_SIZE)\n",
        "valid_loader = make_loader(valid_dataset, BATCH_SIZE)\n",
        "test_loader  = make_loader(test_dataset, BATCH_SIZE)\n",
        "print('check dataset and batch size,')\n",
        "\n",
        "print(f'train data length       : {len(en_train_lst)}')\n",
        "print(f'train data loader length: {len(train_loader)}')\n",
        "print(f'train data loader length: {len(en_train_lst) / BATCH_SIZE}\\n')\n",
        "\n",
        "print(f'valid data length       : {len(en_valid_lst)}')\n",
        "print(f'valid data loader length: {len(valid_loader)}')\n",
        "print(f'valid data loader length: {len(en_valid_lst) / BATCH_SIZE}\\n')\n",
        "\n",
        "print(f'test data length       : {len(en_test_lst)}')\n",
        "print(f'test data loader length: {len(test_loader)}')\n",
        "print(f'test data loader length: {len(en_test_lst) / BATCH_SIZE}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggu-VvWnA5hR",
        "outputId": "a6c8e5a3-1beb-4e83-b8a0-b73784ab5edd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "check dataset and batch size,\n",
            "train data length       : 29001\n",
            "train data loader length: 454\n",
            "train data loader length: 453.140625\n",
            "\n",
            "valid data length       : 1015\n",
            "valid data loader length: 16\n",
            "valid data loader length: 15.859375\n",
            "\n",
            "test data length       : 1000\n",
            "test data loader length: 16\n",
            "test data loader length: 15.625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### multi-head attention, position-wise feed forward"
      ],
      "metadata": {
        "id": "rSD1lAtLEWQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class MultiHeadAttentionLayer(nn.Module):\n",
        "  def __init__(self, HIDDEN_DIM, HEADS, dropout_ratio):\n",
        "    super().__init__()\n",
        "    assert HIDDEN_DIM % HEADS == 0\n",
        "    self.HIDDEN_DIM = HIDDEN_DIM  \n",
        "    self.HEADS      = HEADS\n",
        "    self.HEAD_DIM   = HIDDEN_DIM // HEADS  # n_heads * hidden_dim = head_dim\n",
        "\n",
        "    self.fc_query = nn.Linear(HIDDEN_DIM, HIDDEN_DIM)\n",
        "    self.fc_key   = nn.Linear(HIDDEN_DIM, HIDDEN_DIM)\n",
        "    self.fc_value = nn.Linear(HIDDEN_DIM, HIDDEN_DIM)\n",
        "    self.fc_o     = nn.Linear(HIDDEN_DIM, HIDDEN_DIM)\n",
        "\n",
        "    self.SCALE   = torch.sqrt(torch.FloatTensor([self.HEAD_DIM])).to(DEVICE)\n",
        "    self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "  def forward(self, query, key, value, mask=None):\n",
        "    batch_size = query.shape[0]\n",
        "    # query: [batch_size, query_len, hidden_dim]\n",
        "    # key  : [batch_size, key_len, hidden_dim]\n",
        "    # value: [batch_size, value_len, hidden_dim]\n",
        "\n",
        "    Q = self.fc_query(query)\n",
        "    K = self.fc_key(key)\n",
        "    V = self.fc_value(value)\n",
        "    # Q: [batch_size, query_len, hidden_dim]\n",
        "    # K: [batch_size, key_len, hidden_dim]\n",
        "    # V: [batch_size, value_len, hidden_dim]\n",
        "\n",
        "    # hidden_dim to n_heads * head_dim\n",
        "    Q = Q.view(batch_size, -1, self.HEADS, self.HEAD_DIM).permute(0, 2, 1, 3)\n",
        "    K = K.view(batch_size, -1, self.HEADS, self.HEAD_DIM).permute(0, 2, 1, 3)\n",
        "    V = V.view(batch_size, -1, self.HEADS, self.HEAD_DIM).permute(0, 2, 1, 3)\n",
        "    # Q: [batch_size, n_heads, query_len, head_dim]\n",
        "    # K: [batch_size, n_heads, key_len, head_dim]\n",
        "    # V: [batch_size, n_heads, value_len, head_dim]\n",
        "\n",
        "    # attention energies, (Q*K^T/n)\n",
        "    energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.SCALE\n",
        "    # energy: [batch_size, n_heads, query_len, key_len]\n",
        "\n",
        "    # masking\n",
        "    if mask is not None:\n",
        "      energy = energy.masked_fill(mask==0, -1e10)\n",
        "\n",
        "    # attention score, softmax(Q*K^T/n)\n",
        "    attention = torch.softmax(energy, dim=-1)\n",
        "    # attention: [batch_size, n_heads, query_len, key_len]\n",
        "\n",
        "    # softmax(Q*K^T/n)*V\n",
        "    x = torch.matmul(self.dropout(attention), V)\n",
        "    # x: [batch_size, n_heads, query_len, head_dim]\n",
        "\n",
        "    x = x.permute(0, 2, 1, 3).contiguous()\n",
        "    x = x.view(batch_size, -1, self.HIDDEN_DIM)\n",
        "    # x: [batch_size, query_len, hidden_dim]\n",
        "    x = self.fc_o(x)\n",
        "    return x, attention\n",
        "\n",
        "\n",
        "class PositionwiseFeedforwardLayer(nn.Module):\n",
        "  def __init__(self, HIDDEN_DIM, PF_DIM, dropout_ratio):\n",
        "    super().__init__()\n",
        "    self.fc_1    = nn.Linear(HIDDEN_DIM, PF_DIM)\n",
        "    self.fc_2    = nn.Linear(PF_DIM, HIDDEN_DIM)\n",
        "    self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # x: [batch_size, seq_len, hidden_dim]\n",
        "\n",
        "    x = self.dropout(torch.relu(self.fc_1(x)))\n",
        "    # x: [batch_size, seq_len, pf_dim]\n",
        "\n",
        "    x = self.fc_2(x)\n",
        "    # x: [batch_size, seq_len, hidden_dim]\n",
        "    return x"
      ],
      "metadata": {
        "id": "QddSV6nPNFvl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### token embedding & positional encoding"
      ],
      "metadata": {
        "id": "yBfQ3hmFy6F6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TokenEmbedding(nn.Module):\n",
        "  def __init__(self, VOCAB_SIZE, HIDDEN_DIM):\n",
        "    super().__init__()\n",
        "    self.HIDDEN_DIM = HIDDEN_DIM\n",
        "    self.embedding  = nn.Embedding(VOCAB_SIZE, HIDDEN_DIM)\n",
        "    self.SCALE      = torch.sqrt(torch.FloatTensor([HIDDEN_DIM])).to(DEVICE)\n",
        "\n",
        "  def forward(self, src):\n",
        "    return self.embedding(src) * self.SCALE"
      ],
      "metadata": {
        "id": "E3ik9qUjy6mS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "  def __init__(self, HIDDEN_DIM, dropout_ratio=0.1, max_length=5000):\n",
        "    super().__init__()\n",
        "    self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "    pos = torch.arange(max_length).unsqueeze(1)\n",
        "    den = torch.exp(torch.arange(0, HIDDEN_DIM, 2) * (-math.log(10000) / HIDDEN_DIM))\n",
        "    \n",
        "    pos_embedding = torch.zeros(max_length, 1, HIDDEN_DIM)\n",
        "    pos_embedding[:, 0, 0::2] = torch.sin(pos * den)\n",
        "    pos_embedding[:, 0, 1::2] = torch.cos(pos * den)\n",
        "    self.register_buffer('pos_embedding', pos_embedding)\n",
        "\n",
        "  def forward(self, token_embedding):\n",
        "    # x: [seq_len, batch_size, hidden_dim]\n",
        "    token_embedding += self.pos_embedding[:token_embedding.size(0), :]\n",
        "    return self.dropout(token_embedding)"
      ],
      "metadata": {
        "id": "VkPofVxszC-2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### transformer encoder"
      ],
      "metadata": {
        "id": "6wIonehfEbtZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "  def __init__(self, HIDDEN_DIM, HEADS, PF_DIM, dropout_ratio):\n",
        "    super().__init__()\n",
        "    self.self_attn_layer_norm = nn.LayerNorm(HIDDEN_DIM)\n",
        "    self.ff_layer_norm        = nn.LayerNorm(HIDDEN_DIM)\n",
        "\n",
        "    self.self_attention           = MultiHeadAttentionLayer(HIDDEN_DIM, HEADS, dropout_ratio)\n",
        "    self.positionwise_feedforward = PositionwiseFeedforwardLayer(HIDDEN_DIM, PF_DIM, dropout_ratio)\n",
        "    self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "  def forward(self, src, src_mask):\n",
        "    # src     : [batch_size, src_len, hidden_dim]\n",
        "    # src_mask: [batch_size, src_len]\n",
        "\n",
        "    # self attention\n",
        "    _src, _ = self.self_attention(src, src, src, src_mask)\n",
        "\n",
        "    # residual connection & layer norm\n",
        "    src = self.self_attn_layer_norm(src + self.dropout(_src))\n",
        "\n",
        "    # position-wise feed forward\n",
        "    _src = self.positionwise_feedforward(src)\n",
        "\n",
        "    # residual connection & layer norm\n",
        "    src = self.ff_layer_norm(src + self.dropout(_src))\n",
        "    return src\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self, INPUT_DIM, HIDDEN_DIM, LAYERS, HEADS, PF_DIM, dropout_ratio, max_length=100):\n",
        "    super().__init__()\n",
        "    self.src_token_embedding = TokenEmbedding(INPUT_DIM, HIDDEN_DIM)\n",
        "    self.positional_encoding = PositionalEncoding(HIDDEN_DIM, dropout_ratio)\n",
        "    self.layers = nn.ModuleList([EncoderLayer(HIDDEN_DIM, HEADS, PF_DIM, dropout_ratio)\n",
        "                                for _ in range(LAYERS)])\n",
        "    \n",
        "    self.scale   = torch.sqrt(torch.FloatTensor([HIDDEN_DIM])).to(DEVICE)\n",
        "    self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "  def forward(self, src, src_mask):\n",
        "    # src     : [batch_size, src_len]\n",
        "    # src_mask: [batch_size, src_len]\n",
        "\n",
        "    src = self.src_token_embedding(src)\n",
        "    src = self.positional_encoding(src)\n",
        "\n",
        "    # forward for all layers\n",
        "    for layer in self.layers:\n",
        "      src = layer(src, src_mask)\n",
        "    # src: [batch_size, src_len, hidden_dim]\n",
        "    return src"
      ],
      "metadata": {
        "id": "doh5YsYZhdTC"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### transformer decoder"
      ],
      "metadata": {
        "id": "9nssrEPAEdaJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "  def __init__(self, HIDDEN_DIM, HEADS, PF_DIM, dropout_ratio):\n",
        "    super().__init__()\n",
        "    self.self_attn_layer_norm  = nn.LayerNorm(HIDDEN_DIM)\n",
        "    self.enc_attn_layer_norm   = nn.LayerNorm(HIDDEN_DIM)\n",
        "    self.ff_layer_norm         = nn.LayerNorm(HIDDEN_DIM)\n",
        "\n",
        "    self.self_attention           = MultiHeadAttentionLayer(HIDDEN_DIM, HEADS, dropout_ratio)\n",
        "    self.encoder_attention        = MultiHeadAttentionLayer(HIDDEN_DIM, HEADS, dropout_ratio)\n",
        "    self.positionwise_feedforward = PositionwiseFeedforwardLayer(HIDDEN_DIM, PF_DIM, dropout_ratio)\n",
        "    self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "  # attention for encoding's output\n",
        "  def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "    # trg     : [batch_size, trg_len, hidden_dim]\n",
        "    # enc_src : [batch_size, src_len, hidden_dim]\n",
        "    # trg_mask: [batch_size, trg_len]\n",
        "    # src_mask: [batch_size, src_len]\n",
        "\n",
        "    # self attention\n",
        "    _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\n",
        "\n",
        "    # residual connection & layer norm\n",
        "    trg = self.self_attn_layer_norm(trg + self.dropout(_trg))\n",
        "\n",
        "    # encoder attention\n",
        "    _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\n",
        "\n",
        "    # residual connection & layer_norm\n",
        "    trg = self.enc_attn_layer_norm(trg + self.dropout(_trg)) \n",
        "\n",
        "    # positionwise feed forward\n",
        "    _trg = self.positionwise_feedforward(trg)\n",
        "\n",
        "    # residual connection & layer norm\n",
        "    trg = self.ff_layer_norm(trg + self.dropout(_trg))\n",
        "\n",
        "    # trg      : [batch_size, trg_len, hidden_dim]\n",
        "    # attention: [batch_size, n_heads, trg_len, src_len]\n",
        "    return trg, attention\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self, OUTPUT_DIM, HIDDEM_DIM, LAYERS, HEADS, PF_DIM, dropout_ratio, max_length=100):\n",
        "    super().__init__()\n",
        "    self.trg_token_embedding = TokenEmbedding(OUTPUT_DIM, HIDDEN_DIM)\n",
        "    self.positional_encoding = PositionalEncoding(HIDDEN_DIM, dropout_ratio)\n",
        "    self.layers = nn.ModuleList([DecoderLayer(HIDDEN_DIM, HEADS, PF_DIM, dropout_ratio)\n",
        "                                for _ in range(LAYERS)])\n",
        "\n",
        "    self.fc_out  = nn.Linear(HIDDEN_DIM, OUTPUT_DIM)\n",
        "    self.scale   = torch.sqrt(torch.FloatTensor([HIDDEN_DIM])).to(DEVICE)\n",
        "    self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "  def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "    # trg     : [batch_size, trg_len]\n",
        "    # enc_src : [batch_size, src_len, hidden_dim]\n",
        "    # trg_mask: [batch_size, trg_len]\n",
        "    # src_mask: [batch_size, src_len]\n",
        "\n",
        "    trg = self.trg_token_embedding(trg)\n",
        "    trg = self.positional_encoding(trg)\n",
        "\n",
        "    for layer in self.layers:\n",
        "      trg, attention = layer(trg, enc_src, trg_mask, src_mask)\n",
        "    # trg      : [batch_size, trg_len, hidden_dim]\n",
        "    # attention: [batch_size, n_heads, trg_len, src_len]\n",
        "\n",
        "    output = self.fc_out(trg)\n",
        "    # output: [batch_size, trg_len, output_dim]\n",
        "    return output, attention"
      ],
      "metadata": {
        "id": "2scO308hSJuu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### transformer"
      ],
      "metadata": {
        "id": "13aUNYgHEgTq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn.Module):\n",
        "  def __init__(self, encoder, decoder, pad_idx):\n",
        "    super().__init__()\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.src_pad_idx, self.trg_pad_idx = pad_idx, pad_idx\n",
        "\n",
        "  # masking for <pad> token\n",
        "  def make_src_mask(self, src):\n",
        "    # src: [batch_size, src_len]\n",
        "\n",
        "    src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "    # src_mask: [batch_size, 1, 1, src_len]\n",
        "    return src_mask\n",
        "\n",
        "  # masking for next tokens in target sentence\n",
        "  def make_trg_mask(self, trg):\n",
        "    # trg: [batch_size, trg_len]\n",
        "\n",
        "    trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "    # trg_pad_mask: [batch_size, 1, 1, trg_len]\n",
        "\n",
        "    trg_len = trg.shape[1]\n",
        "    trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device=DEVICE)).bool()\n",
        "    # trg_sub_mask: [trg_len, trg_len]\n",
        "\n",
        "    trg_mask = trg_pad_mask & trg_sub_mask\n",
        "    # trg_mask: [batch_size, 1, trg_len, trg_len]\n",
        "    return trg_mask\n",
        "\n",
        "  def forward(self, src, trg):\n",
        "    # src: [batch_size, src_len]\n",
        "    # trg: [batch_size, trg_len]\n",
        "\n",
        "    src_mask = self.make_src_mask(src)\n",
        "    trg_mask = self.make_trg_mask(trg)\n",
        "    # src_mask: [batch_size, 1, 1, src_len]\n",
        "    # trg_mask: [batch_size, 1, trg_len, trg_len]\n",
        "\n",
        "    enc_src = self.encoder(src, src_mask)\n",
        "    # enc_src: [batch_size, src_len, hidden_dim]\n",
        "\n",
        "    output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
        "    # output   : [batch_size, trg_len, output_dim]\n",
        "    # attention: [batch_size, n_heads, trg_len, src_len]\n",
        "    return output, attention"
      ],
      "metadata": {
        "id": "EWMM1IfVWoTH"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyper parameters\n",
        "INPUT_DIM, OUTPUT_DIM = len(en_vocab), len(de_vocab)\n",
        "HIDDEN_DIM = 512\n",
        "LAYERS     = 6\n",
        "HEADS      = 8\n",
        "PF_DIM     = 2048\n",
        "DROPOUT    = 0.1"
      ],
      "metadata": {
        "id": "2zNIAxunPfNe"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Encoder(INPUT_DIM, HIDDEN_DIM, LAYERS, HEADS, PF_DIM, DROPOUT)\n",
        "decoder = Decoder(OUTPUT_DIM, HIDDEN_DIM, LAYERS, HEADS, PF_DIM, DROPOUT)\n",
        "model   = Transformer(encoder, decoder, preprocessor.pad_token_id)\n",
        "\n",
        "def count_parameters(model):\n",
        "  return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters.\\n')\n",
        "\n",
        "def initialize_weights(model):\n",
        "  for p in model.parameters():\n",
        "    if p.dim() > 1: nn.init.xavier_uniform_(p)\n",
        "\n",
        "model.apply(initialize_weights)\n",
        "model = model.to(DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpe3_p9FFn9D",
        "outputId": "8d5a94e5-492c-4c71-bd7d-4af8536d8b08"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 55,522,638 trainable parameters.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# using adam optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(),\n",
        "                             lr=0.0001,\n",
        "                             betas=(0.9, 0.98),\n",
        "                             eps=1e-9) \n",
        "\n",
        "# define loss function, ignore for padding value\n",
        "loss_fn = nn.CrossEntropyLoss(ignore_index=preprocessor.pad_token_id)"
      ],
      "metadata": {
        "id": "igxnW68xGW-9"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### training"
      ],
      "metadata": {
        "id": "eQhVrr9KEqTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, iterator, optimizer, loss_fn, clip):\n",
        "  model.train()\n",
        "  epoch_loss = 0\n",
        "\n",
        "  for i, batch in enumerate(iterator):\n",
        "    src, trg = batch[0], batch[1]\n",
        "    \n",
        "    optimizer.zero_grad()  # make gradients zero before backpropagation\n",
        "\n",
        "    output, _ = model(src, trg[:,:-1])        # ignore for target's <eos>\n",
        "    # output: [batch_size, trg_len-1, output_dim]\n",
        "    # trg   : [batch_size, trg_len]\n",
        "\n",
        "    output_dim = output.shape[-1]\n",
        "    output = output.contiguous().view(-1, output_dim)\n",
        "    trg    = trg[:,1:].contiguous().view(-1)  # ignore for target's <sos>\n",
        "    # output: [batch_size * trg_len-1, output_dim]\n",
        "    # trg   : [batch_size * trg_len-1]\n",
        "\n",
        "    loss = loss_fn(output, trg)\n",
        "    epoch_loss += loss.item()\n",
        "\n",
        "    loss.backward()                                           # compute gradient\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), clip)  # gradient clipping\n",
        "    optimizer.step()                                          # update parameters\n",
        "  return epoch_loss / len(iterator)\n",
        "\n",
        "def evaluate(model, iterator, loss_fn):\n",
        "  model.eval()\n",
        "  epoch_loss = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for i, batch in enumerate(iterator):\n",
        "      src, trg = batch[0], batch[1]\n",
        "\n",
        "      output, _ = model(src, trg[:,:-1])        # ignore for target's <eos>\n",
        "      # output: [batch_size, trg_len-1, output_dim]\n",
        "      # trg   : [batch_size, trg_len]\n",
        "\n",
        "      output_dim = output.shape[-1]\n",
        "      output = output.contiguous().view(-1, output_dim)\n",
        "      trg    = trg[:,1:].contiguous().view(-1)  # ignore for target's <sos>\n",
        "      # output: [batch_size * trg_len-1, output_dim]\n",
        "      # trg   : [batch_size * trg_len-1]\n",
        "\n",
        "      loss = loss_fn(output, trg)\n",
        "      epoch_loss += loss.item()\n",
        "  return epoch_loss / len(iterator)\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "  elapsed_time = end_time - start_time\n",
        "  elapsed_mins = int(elapsed_time / 60)\n",
        "  elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "  return elapsed_mins, elapsed_secs"
      ],
      "metadata": {
        "id": "IAzUAjWwIp3z"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "EPOCHS = 10\n",
        "CLIP   = 1\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start_time = time.time()\n",
        "\n",
        "  train_loss = train(model, train_loader, optimizer, loss_fn, CLIP)\n",
        "  valid_loss = evaluate(model, valid_loader, loss_fn)\n",
        "\n",
        "  end_time = time.time()\n",
        "  epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "  if valid_loss < best_valid_loss:\n",
        "    best_valid_loss = valid_loss\n",
        "    torch.save(model.state_dict(), 'transformer_en_to_de.pt')\n",
        "\n",
        "  print(f'Epoch: {epoch + 1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "  print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):.3f}')\n",
        "  print(f'\\tValidation Loss: {valid_loss:.3f} | Validation PPL: {math.exp(valid_loss):.3f}')\n",
        "  print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZNjQRGkP0Kh",
        "outputId": "5a99c8fe-cb7e-46c4-cdf0-9fcc3fb058d3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Time: 1m 0s\n",
            "\tTrain Loss: 5.412 | Train PPL: 224.045\n",
            "\tValidation Loss: 4.656 | Validation PPL: 105.235\n",
            "\n",
            "\n",
            "Epoch: 02 | Time: 0m 59s\n",
            "\tTrain Loss: 4.464 | Train PPL: 86.848\n",
            "\tValidation Loss: 4.105 | Validation PPL: 60.638\n",
            "\n",
            "\n",
            "Epoch: 03 | Time: 1m 0s\n",
            "\tTrain Loss: 3.913 | Train PPL: 50.064\n",
            "\tValidation Loss: 3.682 | Validation PPL: 39.743\n",
            "\n",
            "\n",
            "Epoch: 04 | Time: 1m 1s\n",
            "\tTrain Loss: 3.594 | Train PPL: 36.392\n",
            "\tValidation Loss: 3.424 | Validation PPL: 30.699\n",
            "\n",
            "\n",
            "Epoch: 05 | Time: 1m 1s\n",
            "\tTrain Loss: 3.363 | Train PPL: 28.881\n",
            "\tValidation Loss: 3.240 | Validation PPL: 25.522\n",
            "\n",
            "\n",
            "Epoch: 06 | Time: 1m 1s\n",
            "\tTrain Loss: 3.160 | Train PPL: 23.560\n",
            "\tValidation Loss: 3.063 | Validation PPL: 21.387\n",
            "\n",
            "\n",
            "Epoch: 07 | Time: 1m 1s\n",
            "\tTrain Loss: 2.979 | Train PPL: 19.672\n",
            "\tValidation Loss: 2.919 | Validation PPL: 18.515\n",
            "\n",
            "\n",
            "Epoch: 08 | Time: 1m 1s\n",
            "\tTrain Loss: 2.828 | Train PPL: 16.917\n",
            "\tValidation Loss: 2.819 | Validation PPL: 16.753\n",
            "\n",
            "\n",
            "Epoch: 09 | Time: 1m 1s\n",
            "\tTrain Loss: 2.698 | Train PPL: 14.846\n",
            "\tValidation Loss: 2.711 | Validation PPL: 15.043\n",
            "\n",
            "\n",
            "Epoch: 10 | Time: 1m 1s\n",
            "\tTrain Loss: 2.579 | Train PPL: 13.184\n",
            "\tValidation Loss: 2.636 | Validation PPL: 13.961\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download saved model\n",
        "from google.colab import files\n",
        "files.download('transformer_en_to_de.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "rGWFxBfYjmmx",
        "outputId": "2269d959-289e-46d7-cb24-94f292925f42"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b0ddf3d6-3ad8-4ce0-a75b-d43ff2e51c41\", \"transformer_en_to_de.pt\", 242669885)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### testing"
      ],
      "metadata": {
        "id": "iL3-6GxGEuBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load saved model\n",
        "model.load_state_dict(torch.load('./transformer_en_to_de.pt'))\n",
        "\n",
        "# test\n",
        "test_loss = evaluate(model, test_loader, loss_fn)\n",
        "print(f'Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7usX9yPjy1O",
        "outputId": "d2de9439-6bda-445a-ca2b-5e61f83bac24"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 2.627 | Test PPL: 13.836\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# translation using my model\n",
        "def translate_sentence(sentence, preprocessor, model, max_len=50):\n",
        "  model.eval()\n",
        "\n",
        "  # make source indices\n",
        "  src_indices = preprocessor.src_encode(sentence)\n",
        "  src_indices = [preprocessor.sos_token_id] + src_indices + [preprocessor.eos_token_id]\n",
        "\n",
        "  # using encoder\n",
        "  src_tensor = torch.LongTensor(src_indices).unsqueeze(0).to(DEVICE)\n",
        "  src_mask   = model.make_src_mask(src_tensor)\n",
        "  with torch.no_grad():\n",
        "    enc_src = model.encoder(src_tensor, src_mask)\n",
        "\n",
        "  # using decoder, make translated target indices\n",
        "  trg_indices = [preprocessor.sos_token_id]            # has <sos> token\n",
        "  for i in range(max_len):\n",
        "    trg_tensor = torch.LongTensor(trg_indices).unsqueeze(0).to(DEVICE)\n",
        "    trg_mask   = model.make_trg_mask(trg_tensor)\n",
        "    with torch.no_grad():\n",
        "      output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\n",
        "\n",
        "    pred_token = output.argmax(2)[:,-1].item()\n",
        "    if pred_token == preprocessor.eos_token_id: break  # break when <eos> token\n",
        "    else: trg_indices.append(pred_token)\n",
        "\n",
        "  # convert indices to words\n",
        "  trg_tokens = [preprocessor.tgt_id2token[id] for id in trg_indices]\n",
        "  return trg_tokens[1:], attention                     # remove <sos> token"
      ],
      "metadata": {
        "id": "-G-QCacMkLUO"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, batch in enumerate(test_dataset):\n",
        "  if i == 10:\n",
        "    src, tgt = batch[0], batch[1]\n",
        "    break\n",
        "src = preprocessor.src_decode(src)\n",
        "tgt = preprocessor.tgt_decode(tgt)\n",
        "print('original en sentence:')\n",
        "print(f'\\t{src}')\n",
        "print('original de sentence:')\n",
        "print(f'\\t{tgt}')\n",
        "\n",
        "translation, _ = translate_sentence(src, preprocessor, model)\n",
        "translation = ' '.join(translation)\n",
        "print('translated de sentence:')\n",
        "print(f'\\t{translation}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vd2yQwDYVRgx",
        "outputId": "cb81136d-47f9-4256-fdfa-95a2675d8ea7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original en sentence:\n",
            "\tA mother and her young song enjoying a beautiful day outside .\n",
            "original de sentence:\n",
            "\tEine Mutter und ihr kleiner Sohn genießen einen schönen Tag im Freien .\n",
            "translated de sentence:\n",
            "\tEine junge Frau sitzt auf einem <unk> und genießt ihre <unk> .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for bleu score\n",
        "!pip install torchtext==0.6.0"
      ],
      "metadata": {
        "id": "dbO9T5CDKuS3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "outputId": "c160babb-791d-4dd4-e01c-5e247c9ed4eb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchtext==0.6.0\n",
            "  Downloading torchtext-0.6.0-py3-none-any.whl (64 kB)\n",
            "\u001b[K     |████████████████████████████████| 64 kB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.21.6)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 42.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (2.23.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.12.1+cu113)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (4.64.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (1.24.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchtext==0.6.0) (4.1.1)\n",
            "Installing collected packages: sentencepiece, torchtext\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.13.1\n",
            "    Uninstalling torchtext-0.13.1:\n",
            "      Successfully uninstalled torchtext-0.13.1\n",
            "Successfully installed sentencepiece-0.1.97 torchtext-0.6.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torchtext"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.data.metrics import bleu_score\n",
        "\n",
        "def show_bleu(data, preprocessor, model, max_len=50):\n",
        "  trgs, pred_trgs = [], []\n",
        "  for i in range(len(data)):\n",
        "    # original target\n",
        "    src, trg = data[i][0], data[i][1]\n",
        "    src = preprocessor.src_decode(src)\n",
        "    trg = preprocessor.tgt_decode(trg).split(' ')\n",
        "    trgs.append([trg])\n",
        "\n",
        "    # predicted target\n",
        "    pred_trg, _ = translate_sentence(src, preprocessor, model, max_len)\n",
        "    pred_trg = pred_trg[:-1]\n",
        "    pred_trgs.append(pred_trg)\n",
        "\n",
        "    if (i + 1)%100 == 0:\n",
        "      print(f\"[{i+1}/{len(data)}]\")\n",
        "      print(f\"정답: {trg}\")\n",
        "      print(f\"예측: {pred_trg}\\n\")\n",
        "\n",
        "  bleu = bleu_score(pred_trgs, trgs, max_n=4, weights=[0.25, 0.25, 0.25, 0.25])\n",
        "  print(f'Total BLEU Score = {bleu*100:.2f}')\n",
        "\n",
        "  bleu1_score = bleu_score(pred_trgs, trgs, max_n=4, weights=[1, 0, 0, 0])\n",
        "  bleu2_score = bleu_score(pred_trgs, trgs, max_n=4, weights=[0, 1, 0, 0])\n",
        "  bleu3_score = bleu_score(pred_trgs, trgs, max_n=4, weights=[0, 0, 1, 0])\n",
        "  bleu4_score = bleu_score(pred_trgs, trgs, max_n=4, weights=[0, 0, 0, 1])\n",
        "  print(f'BLEU1 score = {bleu1_score}') \n",
        "  print(f'BLEU2 score = {bleu2_score}') \n",
        "  print(f'BLEU3 score = {bleu3_score}') \n",
        "  print(f'BLEU4 score = {bleu4_score}') \n",
        "\n",
        "show_bleu(test_dataset, preprocessor, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vjjmi4DGo-Tt",
        "outputId": "94a8f889-51bd-4e2b-d3d8-81d4ea687239"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100/1000]\n",
            "정답: ['Ein', 'kleiner', 'Junge', 'im', 'Fußballdress', 'hält', 'die', 'Hände', '<unk>', 'Gesicht', 'und', 'weint', '.']\n",
            "예측: ['Ein', 'kleiner', 'Junge', 'in', 'einem', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>']\n",
            "\n",
            "[200/1000]\n",
            "정답: ['Ein', 'Mann', 'macht', 'Werbung', 'mit', 'einem', 'riesigen', 'Schild', ',', 'das', 'auf', 'sein', 'Fahrrad', 'gebunden', 'ist', '.']\n",
            "예측: ['Ein', 'Mann', 'mit', 'einem', '<unk>', '<unk>', '<unk>', 'auf', 'einem', '<unk>']\n",
            "\n",
            "[300/1000]\n",
            "정답: ['Eine', 'Gruppe', 'junger', 'Menschen', 'trinkt', '<unk>', 'in', 'einem', '<unk>', '<unk>', '.']\n",
            "예측: ['Eine', 'Gruppe', 'junger', 'junger', 'junger', 'Menschen', 'macht', 'eine', '<unk>', 'in', 'der', 'Nähe', 'eines', '<unk>']\n",
            "\n",
            "[400/1000]\n",
            "정답: ['Ein', 'lächelnder', 'Junge', 'spielt', 'im', 'Laub', 'mit', 'den', 'Enten', '.']\n",
            "예측: ['Ein', 'kleiner', 'Junge', 'spielt', 'im', 'Freien', 'mit', '<unk>']\n",
            "\n",
            "[500/1000]\n",
            "정답: ['Eine', 'Frau', 'steht', 'auf', 'einem', 'grünen', 'Feld', ',', 'hält', 'einen', 'weißen', 'Hund', 'und', 'zeigt', 'auf', 'einen', 'braunen', 'Hund', '.']\n",
            "예측: ['Eine', 'Frau', 'mit', 'einem', 'roten', 'Hund', 'und', 'einem', 'braunen', 'Hund', 'stehen', 'neben', 'einem', 'großen', '<unk>']\n",
            "\n",
            "[600/1000]\n",
            "정답: ['Ein', 'Typ', 'in', 'einem', 'gelben', 'Outfit', 'steht', 'hinter', 'dem', 'Mikrofon', 'in', 'einem', 'Zelt', '.']\n",
            "예측: ['Ein', 'Mann', 'in', 'einem', 'blauen', 'Hemd', 'sitzt', 'vor', 'einem', '<unk>']\n",
            "\n",
            "[700/1000]\n",
            "정답: ['Zwei', 'Motocrossfahrer', 'in', 'voller', 'Schutzkleidung', ',', 'einer', 'von', 'ihnen', 'ist', 'nach', 'einem', 'Sprung', 'in', 'der', 'Luft', ',', 'der', 'andere', 'blickt', 'auf', 'sein', 'Motorrad', 'hinunter', '.']\n",
            "예측: ['Zwei', 'Radfahrer', 'in', '<unk>', 'und', 'mit', 'der', 'Nummer', '<unk>', 'in', 'der', 'Luft']\n",
            "\n",
            "[800/1000]\n",
            "정답: ['Ein', 'Mann', 'sitzt', 'auf', 'einer', 'Plattform', 'mit', 'Rädern', 'und', 'wird', 'an', 'einem', 'Loch', '<unk>', '.']\n",
            "예측: ['Ein', 'Mann', 'mit', 'einem', '<unk>', 'auf', 'einem', '<unk>']\n",
            "\n",
            "[900/1000]\n",
            "정답: ['Eine', 'Person', 'in', 'Blau', 'wirft', 'auf', 'einer', 'Bowlingbahn', 'als', '<unk>', 'ihre', 'Kugel', '.']\n",
            "예측: ['Eine', 'Person', 'macht', 'ein', '<unk>', 'in', 'der', 'Luft']\n",
            "\n",
            "[1000/1000]\n",
            "정답: ['Ein', 'Mädchen', 'an', 'einer', 'Küste', 'mit', 'einem', 'Berg', 'im', 'Hintergrund', '.']\n",
            "예측: ['Ein', 'Mädchen', 'geht', 'auf', 'einem', 'Gehweg', 'mit', 'einem', 'kleinen', 'Mädchen', 'im', 'Hintergrund']\n",
            "\n",
            "Total BLEU Score = 10.31\n",
            "BLEU1 score = 0.36997822643168077\n",
            "BLEU2 score = 0.1547971238426698\n",
            "BLEU3 score = 0.06800463404635128\n",
            "BLEU4 score = 0.029053456899519953\n"
          ]
        }
      ]
    }
  ]
}